{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAHl-_khxVG9"
   },
   "source": [
    "**Steps of Sales Prediction Problem**\n",
    "\n",
    "* **Hypothesis Generation** – understanding the problem better by brainstorming possible factors that can impact the outcome\n",
    "* **Data Exploration** – looking at categorical and continuous feature summaries and making inferences about the data.\n",
    "* **Data Cleaning** – imputing missing values in the data and checking for outliers\n",
    "* **Feature Engineering** – modifying existing variables and creating new ones for analysis\n",
    "* **Model Building** – making predictive models on the data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KG1-6mcww_83"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "#readfiles\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "8YO2J_4z12mB",
    "outputId": "72c7a4c4-6b86-40e5-d4c6-1c7310353301"
   },
   "outputs": [],
   "source": [
    "#Mount Google Drive for file path\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtxcstMy06uj"
   },
   "outputs": [],
   "source": [
    "#upload files\n",
    "#uploaded = files.upload()\n",
    "url = \"/content/drive/My Drive/Colab Notebooks/data-big-mart/Train.csv\";\n",
    "train = pd.read_csv(url);\n",
    "url = \"/content/drive/My Drive/Colab Notebooks/data-big-mart/Test.csv\";\n",
    "test = pd.read_csv(url);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "bsqPyv872QYD",
    "outputId": "b13b88bf-a3e1-411d-f221-299a73d8b2ba"
   },
   "outputs": [],
   "source": [
    "print(train.shape, test.shape);\n",
    "print(train.sample(5), test.sample(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CViUbzbL3z_U",
    "outputId": "3efebe45-1726-4b45-c125-1b66eb37732e"
   },
   "outputs": [],
   "source": [
    "#combining the dataset with a source column to record where each observation belong\n",
    "train['source'] = 'train';\n",
    "test['source'] = 'test';\n",
    "\n",
    "data = pd.concat([train, test],ignore_index=True, sort=False);\n",
    "print (train.shape, test.shape, data.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "gOrB0O1Z4pkm",
    "outputId": "a7a5128b-30c7-4fdf-d446-ca98aeace1fa"
   },
   "outputs": [],
   "source": [
    "#Checking for Missing Values in all Numerical variables\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9jXRLJB7l2K"
   },
   "source": [
    "Item Outlet Sales is our target variable and the missing values are from  the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "7oTAxPww7uAu",
    "outputId": "cdd513f9-d8d3-48c3-bd43-821061ee82ba"
   },
   "outputs": [],
   "source": [
    "#checking the unique values for all categorical variables\n",
    "data.apply(lambda x:len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "SOsP5LJA88wb",
    "outputId": "6e6d9f87-f838-41ba-aa2d-4016457b0d97"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "aVeb_7IZ_mfI",
    "outputId": "1dae829b-efab-4e3e-8d85-4deeef76f5a8"
   },
   "outputs": [],
   "source": [
    "missing_values_count = ((data.isnull().sum()/data.isnull().count())*100).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('No of missing values in %ge', fontsize=15)\n",
    "plt.title('Top 10 Variables with missing data', fontsize=15)\n",
    "sns.barplot(missing_values_count[:10].index.values, missing_values_count[:10],palette=\"hls\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uwwn_PaKINjz"
   },
   "source": [
    "So, we can exclude Item_Outlet_sales since the missing values are from test set. we should treat Outlet_Size and Item_Weight features for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iInNjuXhIjC4"
   },
   "outputs": [],
   "source": [
    "#Treating Missing Values\n",
    "#we will add avg item weight to the missing values\n",
    "#full_ds[\"LotFrontage\"] = full_ds.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median())) \n",
    "data['Item_Weight'].isnull().sum()\n",
    "data['Item_Weight'] = data['Item_Weight'].fillna(data['Item_Weight'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8FqiNFLNbPaJ",
    "outputId": "3e6ff0ff-e641-4b40-d16b-5934d954e835"
   },
   "outputs": [],
   "source": [
    "#Outlet Size\n",
    "data['Outlet_Size'] = data[\"Outlet_Size\"].fillna(data[\"Outlet_Size\"].mode()[0])\n",
    "\n",
    "print (data['Item_Weight'].isnull().sum())\n",
    "print (data['Item_Weight'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kjLYsg89CCEe",
    "outputId": "1389f8bb-8194-40dd-c670-4991801a12c6"
   },
   "outputs": [],
   "source": [
    "#Filter Categorical Variables & Explore frequency of different categories in categorical variable\n",
    "#Seleting all Categorial Features\n",
    "categorical_feats = data.dtypes[data.dtypes == \"object\"].index\n",
    "#categorical_feats\n",
    "#categorical_clm = [x for x in data.dtypes.index if data.dtypes[x]=='object']\n",
    "#Exclude ID and Source column\n",
    "#categorical_feats.drop('Item_Identifier',axis = 1, inplace= True)\n",
    "#train.drop(\"Id\", axis = 1, inplace = True)\n",
    "categorical_feats = [x for x in categorical_feats if x not in ['Item_Identifier','Outlet_Identifier','source']]\n",
    "print (categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "jGzo3cCdGOQq",
    "outputId": "ef327983-c00b-4950-fe36-1090de0dfe86"
   },
   "outputs": [],
   "source": [
    "#Printing Frequency of Categories:\n",
    "for col in categorical_feats:\n",
    "  print (\"\\n Frequency of Categories for variable: %s\"%col)\n",
    "  print (data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z6WfXk77HvjD",
    "outputId": "4cc411db-3298-469a-9593-1cf51b867516"
   },
   "outputs": [],
   "source": [
    "#Missing values treatment for Item_Visibility, filling with mean value\n",
    "#data = data.set_index(data['Item_Visibility'])\n",
    "data['Item_Visibility'] = data[\"Item_Visibility\"].replace(0,data['Item_Visibility'].mean())\n",
    "#print (data.loc[data['Item_Visibility']==0].count())\n",
    "print ('0 Values after modification %s' %sum(data['Item_Visibility']==0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "uyt2qUb-btIC",
    "outputId": "10ae2490-526e-483f-dfd4-e4acc319a98f"
   },
   "outputs": [],
   "source": [
    "#Get the first two characters of ID:\n",
    "data['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "#Rename them to more intuitive categories:\n",
    "data['Item_Type_Combined'] = data['Item_Type_Combined'].map({'FD':'Food',\n",
    "                                                             'NC':'Non-Consumable',\n",
    "                                                             'DR':'Drinks'})\n",
    "data['Item_Type_Combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "8hCPhGj2cDOu",
    "outputId": "10ffee35-cb37-45c0-f9e2-5ff45b5c11d2"
   },
   "outputs": [],
   "source": [
    "#Years:\n",
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "data['Outlet_Years'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "nDVk5um-cOZE",
    "outputId": "1622438a-734a-4a4b-b4de-b720b3721665"
   },
   "outputs": [],
   "source": [
    "#Change categories of low fat:\n",
    "print ('Original Categories:')\n",
    "print (data['Item_Fat_Content'].value_counts())\n",
    "\n",
    "print ('\\nModified Categories:')\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print (data['Item_Fat_Content'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yPOCQNTtcpUK",
    "outputId": "3c738a25-32b2-4b60-c057-7131ab0fef08"
   },
   "outputs": [],
   "source": [
    "#Mark Non-Consumables as seperate categary in low_fat\n",
    "data.loc[data['Item_Type_Combined']==\"Non-Consumable\",\"Item_Fat_Content\"]=\"Non-Edible\"\n",
    "data['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_VtzH-Kfi-3"
   },
   "outputs": [],
   "source": [
    "#Step 6: numerical and hot encoding\n",
    "#Lets start with coding all categorical variables as numeric using ‘LabelEncoder’ from sklearn’s preprocessing module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "#new Variable for Outlet\n",
    "\n",
    "data['Outlet'] = le.fit_transform(data['Outlet_Identifier'])\n",
    "var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "  data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "09cyBUrtg65Q",
    "outputId": "d76da5a3-dcb0-4b16-f169-8941e4579ea7"
   },
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "\n",
    "data = pd.get_dummies(data, columns=['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet'])\n",
    "\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "MormlEo9iefk",
    "outputId": "f55e044d-9e54-4236-9ede-ed5d0df72d7a"
   },
   "outputs": [],
   "source": [
    "data[['Item_Fat_Content_0','Item_Fat_Content_1','Item_Fat_Content_2']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "KQeljkb0iiAP",
    "outputId": "cf2d56b5-027e-43d1-bdbc-d36aa53bc28a"
   },
   "outputs": [],
   "source": [
    "#Step 7: Convert data back into train and test set\n",
    "#Dropping columns which have been converted to different types\n",
    "data.drop(['Item_Type','Outlet_Establishment_Year'],axis=1,inplace=True)\n",
    "\n",
    "#Divinde in Test and train\n",
    "train = data.loc[data['source']=='train']\n",
    "test = data.loc[data['source']=='test']\n",
    "\n",
    "#Drop Unnecessary columns\n",
    "\n",
    "test.drop(['Item_Outlet_Sales','source'],axis=1,inplace=True)\n",
    "train.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "#Export files as modified versions:\n",
    "train.to_csv(\"train_modified.csv\",index=False)\n",
    "test.to_csv(\"test_modified.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTG8mQGjl8xd"
   },
   "outputs": [],
   "source": [
    "#Model Building\n",
    "#Lets start by making a baseline model. Baseline model is the one which requires no predictive model and \n",
    "#its like an informed guess. For instance, in this case lets predict the sales as the overall average sales. \n",
    "\n",
    "mean_sales = train['Item_Outlet_Sales'].mean()\n",
    "\n",
    "#Define Dataframe with ID's for Submission\n",
    "\n",
    "base1 = test[['Item_Identifier','Outlet_Identifier']]\n",
    "\n",
    "base1['Item_Outlet_Sales'] = mean_sales\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bsVstyMnXQD"
   },
   "outputs": [],
   "source": [
    "#I would like to define a generic function which takes the algorithm and data as input and makes the model, performs cross-validation and generates submission.\n",
    "#Define Target & ID Columns\n",
    "\n",
    "target = 'Item_Outlet_Sales'\n",
    "IDcol = ['Item_Identifier','Outlet_Identifier']\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "def modelfit(alg, dtrain, dtest, predictors, target, IDcol, filename):\n",
    "  #fit the algorithm to the data\n",
    "  alg.fit(dtrain[predictors],dtrain[target])\n",
    "  \n",
    "  #Predict training set:\n",
    "  dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "  \n",
    "  #Perform Cross Validation\n",
    "  cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=20, scoring ='neg_mean_squared_error')\n",
    "  cv_score = np.sqrt(np.abs(cv_score))\n",
    "  \n",
    "  #print model report\n",
    "  \n",
    "  print (\"\\nModel Report:\")\n",
    "  print (\"RMSE: %.4g\"%np.sqrt(metrics.mean_squared_error(dtrain[target].values,dtrain_predictions)))\n",
    "# print (\"CV Score: Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" %np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "  print (\"CV Score: Mean - {0} | Std - {1} | Min - {2} | Max - {3}\".format(np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "\n",
    "  #Predict on Test Data\n",
    "  dtest[target] = alg.predict(dtest[predictors])\n",
    "  \n",
    "  IDcol.append(target)\n",
    "  \n",
    "  submission = pd.DataFrame({x: dtest[x] for x in IDcol})\n",
    "  submission.to_csv(filename, index=False)\n",
    "  \n",
    "  \n",
    "  \n",
    "#linear_reg = LinearRegression()\n",
    "#linear_reg.fit(X_train,y)\n",
    "#mean_sq_er = cross_val_score(linear_reg,X_train,y,scoring='neg_mean_squared_error',cv=5)\n",
    "#rmse_lin = rmse_cross_val(linear_reg)\n",
    "#print(\"Mean Squared Error\",mean_sq_er.mean())\n",
    "#print(\"Root Mean Squared Error\",rmse_lin.mean())\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P80X6vXKqwaS"
   },
   "source": [
    "**Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "it9hS8ZPqvuD",
    "outputId": "c178c4e4-0c7d-4f37-c59c-7958c4c8f873"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "\n",
    "#Print Predictors\n",
    "\n",
    "alg1 = LinearRegression(normalize=True)\n",
    "modelfit(alg1, train, test, predictors, target, IDcol,'1-lr.csv' )\n",
    "coef1 = pd.Series(alg1.coef_, predictors).sort_values()\n",
    "plt.figure(figsize=(15,10))\n",
    "coef1.plot(kind='bar', title=\"Linear Model Coefficients\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "b3gse30ly3YF",
    "outputId": "3282442d-2bb1-42d3-97b2-c936d528dc5b"
   },
   "outputs": [],
   "source": [
    "#Ridge Regression Model:\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg2 = Ridge(alpha=0.05, normalize=True)\n",
    "modelfit(alg2, train, test, predictors, target, IDcol,'2-ridge.csv' )\n",
    "coef2 = pd.Series(alg2.coef_, predictors).sort_values()\n",
    "plt.figure(figsize=(15,10))\n",
    "coef2.plot(kind='bar', title=\"Ridge Model Coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "BeyQ1paC1AsD",
    "outputId": "3dbfe52e-2cf6-4fd9-83d5-eec13a2b61c5"
   },
   "outputs": [],
   "source": [
    "#Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg3 = DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\n",
    "modelfit(alg3, train, test, predictors, target, IDcol,'3-decision-tree.csv' )\n",
    "coef3 = pd.Series(alg3.feature_importances_, predictors).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,10))\n",
    "coef3.plot(kind='bar', title=\"Decision Tree Feature Importances\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E64hRr4F17F4"
   },
   "source": [
    "Here you can see that the RMSE is 1058 and the mean CV error is 1091. This tells us that the model is slightly overfitting. Lets try making a decision tree with just top 4 variables, a max_depth of 8 and min_samples_leaf as 150.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "colab_type": "code",
    "id": "wvDjVdRK18XV",
    "outputId": "7b12a6d7-ec7c-4076-acfd-2add0fb8917d"
   },
   "outputs": [],
   "source": [
    "predictors = ['Item_MRP','Outlet_Type_0','Outlet_Type_3','Outlet_5','Outlet_Years']\n",
    "alg4 = DecisionTreeRegressor(max_depth=8, min_samples_leaf=150)\n",
    "modelfit(alg4, train, test, predictors, target, IDcol,'4-decision-tree.csv' )\n",
    "coef4 = pd.Series(alg4.feature_importances_, predictors).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,10))\n",
    "coef4.plot(kind='bar', title=\"Decision Tree Feature Importances\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "TOWgC46y2nFc",
    "outputId": "7dd7bf45-b232-466b-bfaf-5553c6f9ca86"
   },
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg5 = RandomForestRegressor(n_estimators=200,max_depth=5, min_samples_leaf=100, n_jobs=4)\n",
    "modelfit(alg5, train, test, predictors, target, IDcol,'5-random-forest.csv' )\n",
    "coef5 = pd.Series(alg5.feature_importances_, predictors).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,10))\n",
    "coef5.plot(kind='bar', title=\"Random Forest Feature Importances\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "eemyWeP23qZW",
    "outputId": "f546d958-8dbb-4568-da19-8d4991253051"
   },
   "outputs": [],
   "source": [
    "#Random Forest Model - revised\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg6 = RandomForestRegressor(n_estimators=400,max_depth=6, min_samples_leaf=100, n_jobs=4)\n",
    "modelfit(alg6, train, test, predictors, target, IDcol,'6-random-forest.csv' )\n",
    "coef6 = pd.Series(alg6.feature_importances_, predictors).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,10))\n",
    "coef6.plot(kind='bar', title=\"Random Forest Feature Importances\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Big Mart  Sales Prediction Problem",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}